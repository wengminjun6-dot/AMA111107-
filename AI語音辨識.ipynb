{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1f8436jGcItayBm9gdZ3GzJpN5ts9bJGv",
      "authorship_tag": "ABX9TyPZ8WqOXz+JVjgLovYpOJIX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wengminjun6-dot/AMA111107-/blob/main/AI%E8%AA%9E%E9%9F%B3%E8%BE%A8%E8%AD%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cs_kpKb1fJQR",
        "outputId": "a54b7495-ee64-4483-c4f0-e5dd304f2a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "pip install openai-whisper\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prg1 語音轉文字\n",
        "\n",
        "import whisper\n",
        "\n",
        "# 載入 Whisper 模型（tiny / base / small / medium / large 可選）\n",
        "# tiny 速度快但準確度低，large 最準確但需要 GPU 記憶體\n",
        "model = whisper.load_model(\"large\")\n",
        "\n",
        "# 讀取 wav 檔案\n",
        "audio_file = \"/content/drive/MyDrive/luvvoice.com-20251015-OkRBdH.mp3\" # 使用 Google 雲端硬碟的檔案路徑\n",
        "\n",
        "# 轉文字\n",
        "result = model.transcribe(audio_file, language=\"zh\")\n",
        "\n",
        "# 印出逐字稿\n",
        "print(\"逐字稿內容：\")\n",
        "print(result[\"text\"])\n",
        "\n",
        "# 也可以存成文字檔\n",
        "with open(\"transcript.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH7b8GsRh5dE",
        "outputId": "d8c3082d-5d38-4640-cca3-af2a0c9b5ecc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "逐字稿內容：\n",
            "本来应该从丛容容游刃有余现在是匆匆忙忙连滚带爬。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "476ab75a",
        "outputId": "0667a60a-89ee-4547-bf1a-4a1f732a0184"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "\n",
        "# Specify the folder containing the audio files\n",
        "audio_folder = \"/content/\"  # Replace with the path to your folder\n",
        "\n",
        "# Load the Whisper model (choose the appropriate model size)\n",
        "# tiny / base / small / medium / large\n",
        "model = whisper.load_model(\"small\")\n",
        "\n",
        "# Iterate through files in the folder\n",
        "for filename in os.listdir(audio_folder):\n",
        "    if filename.endswith(\".mp3\") or filename.endswith(\".wav\"):  # Add other audio formats if needed\n",
        "        audio_file_path = os.path.join(audio_folder, filename)\n",
        "        print(f\"Processing: {audio_file_path}\")\n",
        "\n",
        "        try:\n",
        "            # Load audio and detect the language\n",
        "            audio = whisper.load_audio(audio_file_path)\n",
        "            # Pad or trim the audio to 30 seconds\n",
        "            audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "            # Make log-Mel spectrogram and move to the same device as the model\n",
        "            mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "            # Detect the spoken language\n",
        "            _, probs = model.detect_language(mel)\n",
        "            detected_language = max(probs, key=probs.get)\n",
        "            print(f\"Detected language: {detected_language}\")\n",
        "\n",
        "            # Transcribe the audio file using the detected language\n",
        "            result = model.transcribe(audio_file_path, language=detected_language)\n",
        "\n",
        "            # Create a transcript filename based on the original filename\n",
        "            transcript_filename = os.path.splitext(filename)[0] + f\"_{detected_language}_transcript.txt\"\n",
        "            transcript_file_path = os.path.join(audio_folder, transcript_filename)\n",
        "\n",
        "            # Save the transcript to a text file\n",
        "            with open(transcript_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(result[\"text\"])\n",
        "\n",
        "            print(f\"Transcript saved to: {transcript_file_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "print(\"Batch processing complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLvZd41Oh895",
        "outputId": "99004453-f95c-4f99-8100-783a6cf31c72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch processing complete.\n"
          ]
        }
      ]
    }
  ]
}